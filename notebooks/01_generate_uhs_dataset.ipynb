{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab35df0",
   "metadata": {},
   "source": [
    "# 01 – Generate SUHS‑MRV UHS Dataset\n",
    "\n",
    "This notebook regenerates the **SUHS‑MRV v2.0** Underground Hydrogen Storage dataset using `src/generator.py`.\n",
    "\n",
    "It will:\n",
    "\n",
    "1. Add the repository root to `sys.path` so `src` can be imported from the `notebooks/` folder.\n",
    "2. Call the dataset generator.\n",
    "3. Show basic information for each generated CSV.\n",
    "\n",
    "Run this notebook from the `notebooks/` directory of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path.cwd()\n",
    "REPO_ROOT = NOTEBOOK_DIR.parent\n",
    "DATA_DIR = REPO_ROOT / 'data' / 'generated'\n",
    "\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "print('Notebook dir:', NOTEBOOK_DIR)\n",
    "print('Repo root   :', REPO_ROOT)\n",
    "print('Data dir    :', DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfd6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generator import generate_uhs_dataset\n",
    "\n",
    "facility_df, timeseries_df, cycle_summary_df = generate_uhs_dataset()\n",
    "\n",
    "print('Generation complete.')\n",
    "print('facility_metadata rows :', len(facility_df))\n",
    "print('facility_timeseries rows:', len(timeseries_df))\n",
    "print('cycle_summary rows      :', len(cycle_summary_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d7b18",
   "metadata": {},
   "source": [
    "## Inspect generated CSV files on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09128aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for path in sorted(DATA_DIR.glob('*.csv')):\n",
    "    size_kb = path.stat().st_size / 1024.0\n",
    "    print(f\"{path.name:30s}  {size_kb:8.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f6436",
   "metadata": {},
   "source": [
    "## Quick preview of each CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_path = DATA_DIR / 'facility_metadata.csv'\n",
    "facility_df = pd.read_csv(facility_path)\n",
    "facility_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd08e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_path = DATA_DIR / 'facility_timeseries.csv'\n",
    "timeseries_df = pd.read_csv(ts_path, parse_dates=['timestamp'])\n",
    "timeseries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_path = DATA_DIR / 'cycle_summary.csv'\n",
    "cycle_summary_df = pd.read_csv(cycle_path, parse_dates=['cycle_start', 'cycle_end'])\n",
    "cycle_summary_df.head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
